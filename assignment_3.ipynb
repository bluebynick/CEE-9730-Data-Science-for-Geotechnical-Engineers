{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluebynick/CEE-9730-Data-Science-for-Geotechnical-Engineers/blob/Assignments/assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rAc3nggri8nL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "b762175c-c6c8-4420-cd7d-04065f27ec35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-cpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-intel as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras-nightly as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras-preprocessing as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras-vis as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras-applications as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n",
            "tensorflow-decision-forests 1.12.0 requires tf_keras~=2.19, which is not installed.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/drive\n",
            "Paths set. leftImg8bit exists? True\n",
            "gtCoarse exists? True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1486473913.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m#visualize a few image/mask pairs as a sanity check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mimgs_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1486473913.py\u001b[0m in \u001b[0;36mbatch_gen\u001b[0;34m(pairs, batch_size, image_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mimg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mim_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m     \u001b[0;31m# (H,W,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3524\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3526\u001b[0;31m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3528\u001b[0m     \u001b[0mwarning_messages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpreinit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJpegImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mJpegImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#!pip uninstall -y tensorflow tensorflow-cpu tensorflow-intel keras tf-keras keras-nightly keras-preprocessing keras-vis keras-applications\n",
        "#!pip install -q tensorflow\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, glob, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from PIL import Image\n",
        "\n",
        "#variables\n",
        "IMAGE_SIZE = (256, 512);\n",
        "BATCH_SIZE = 8;\n",
        "EPOCHS = 1; #1 so this doesn't take forever\n",
        "N_CLASSES = 12;\n",
        "IGNORE_LABEL = 255\n",
        "histories = {}\n",
        "\n",
        "#get the files. i'd tried with zip files but it ended horribly so i restarted lol\n",
        "leftImg8bit = os.path.join('/content/drive/MyDrive/leftImg8bit_trainvaltest', 'leftImg8bit')\n",
        "gtCoarse = os.path.join('/content/drive/MyDrive/gtCoarse', 'gtCoarse')\n",
        "print(\"Paths set. leftImg8bit exists?\", os.path.exists(leftImg8bit))\n",
        "print(\"gtCoarse exists?\", os.path.exists(gtCoarse))\n",
        "\n",
        "#the paring method\n",
        "#des: a method which catches the image and pairs it to the label. and returns back that list\n",
        "def find_image_label_pairs(split='train'):\n",
        "    #define variables per instance\n",
        "    labels = {}; pairs = []\n",
        "\n",
        "    #for the images\n",
        "    img_pattern = os.path.join(leftImg8bit, split, '*', '*_leftImg8bit.png') #create a list per the image handle\n",
        "    imgs = sorted(glob.glob(img_pattern)) #create a list of images matching the pattern that we established\n",
        "    #glob.glob returns a list of paths matching a pathname pattern - from the docs\n",
        "\n",
        "    #for the labels\n",
        "    #there's two possible label naming conventions so we have to parse through all in a loop\n",
        "    label_pattern1 = os.path.join(gtCoarse, split, '*', '*_gtCoarse_labelTrainIds.png')\n",
        "    label_pattern2 = os.path.join(gtCoarse, split, '*', '*_gtCoarse_labelIds.png')\n",
        "    for p in glob.glob(label_pattern1):\n",
        "        labels[Path(p).stem.replace('_gtCoarse_labelTrainIds','')] = p\n",
        "    for p in glob.glob(label_pattern2):\n",
        "        labels[Path(p).stem.replace('_gtCoarse_labelIds','')] = p\n",
        "    #go through all of #1, get it, assign label to the index, replace it with null in the ram space. then do it to #2\n",
        "\n",
        "    #per each img, get it and replace it's ram spot in ram with null\n",
        "    for img in imgs:\n",
        "        stem = Path(img).stem.replace('_leftImg8bit','')\n",
        "        lab = labels.get(stem)\n",
        "        if lab:\n",
        "            pairs.append((img, lab))\n",
        "        #but get the label associated at that location. then put them together if the label matches the image\n",
        "\n",
        "    return pairs\n",
        "\n",
        "#loading images, resizing them per the nearest neighbour (masks), then remapping the labels,\n",
        "def batch_gen(pairs, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE):\n",
        "    i = 0\n",
        "    while True:\n",
        "        imgs, masks = [], []\n",
        "        for _ in range(batch_size):\n",
        "            img_p, m_p = pairs[i % len(pairs)]\n",
        "            im = Image.open(img_p).convert('RGB').resize((image_size[1],image_size[0]), Image.BILINEAR)\n",
        "            ms = Image.open(m_p).resize((image_size[1],image_size[0]), Image.NEAREST)\n",
        "            im_a = np.asarray(im, np.float32) / 255.0     # (H,W,3)\n",
        "            m_a  = np.asarray(ms, np.int32)               # (H,W)\n",
        "            m_a[m_a == 255] = 0\n",
        "            imgs.append(im_a)\n",
        "            masks.append(m_a);\n",
        "            i += 1\n",
        "        yield np.stack(imgs), np.stack(masks)\n",
        "\n",
        "#this is method which visualizes a few image/mask pairs as a sanity check\n",
        "def show_pair(img, mask, ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "    ax[0].imshow(img); ax[0].set_title(\"Image\"); ax[0].axis('off');\n",
        "    ax[1].imshow(mask, cmap='tab20'); ax[1].set_title(\"Mask\"); ax[1].axis('off')\n",
        "\n",
        "#build the model\n",
        "def build_unet(input_shape=(256,512,3), num_classes=20):\n",
        "    x = inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    #down\n",
        "    c1 = layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n",
        "    p1 = layers.MaxPool2D()(c1)\n",
        "\n",
        "    #bottleneck\n",
        "    b  = layers.Conv2D(32, 3, padding='same', activation='relu')(p1)\n",
        "\n",
        "    #up\n",
        "    u1 = layers.UpSampling2D()(b)\n",
        "    u1 = layers.Concatenate()([u1, c1])\n",
        "    c2 = layers.Conv2D(16, 3, padding='same', activation='relu')(u1)\n",
        "\n",
        "    out = layers.Conv2D(num_classes, 1, activation='softmax')(c2)\n",
        "    return Model(inputs, out)\n",
        "\n",
        "#let's run this bad boy\n",
        "#pass the different folders we have to the pairing method. idk if i should pass test / train_extra too tho\n",
        "train_pairs = find_image_label_pairs('train')\n",
        "val_pairs = find_image_label_pairs('val'); #print(\"Found pairs:\", len(train_pairs), \"train |\", len(val_pairs), \"val\")\n",
        "train_pairs = train_pairs[:200] #limit the lists cause the size is huge\n",
        "val_pairs = val_pairs[:50]; #print(\"Using pairs:\", len(train_pairs), \"train |\", len(val_pairs), \"val\")\n",
        "\n",
        "#pass the list and batch size to the generation + resizing + masking + remapping method\n",
        "train_gen = batch_gen(train_pairs, batch_size=BATCH_SIZE)\n",
        "val_gen   = batch_gen(val_pairs, batch_size=BATCH_SIZE)\n",
        "\n",
        "#visualize a few image/mask pairs as a sanity check\n",
        "imgs_np, masks_np = next(batch_gen(train_pairs, batch_size=3))\n",
        "for i in range(min(3, imgs_np.shape[0])):\n",
        "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
        "    show_pair(imgs_np[i], masks_np[i], ax=axes)\n",
        "    plt.show()\n",
        "\n",
        "#a check that the visual masks are okay. they are\n",
        "#x_batch, y_batch = next(batch_gen(train_pairs, batch_size=1));\n",
        "#print(\"image shape:\", x_batch.shape, \"mask shape:\", y_batch.shape);print(\"mask dtype:\", y_batch.dtype);print(\"unique labels (first 20):\", np.unique(y_batch)[:20]);print(\"max label:\", np.max(y_batch))\n",
        "\n",
        "#i was getting an InvalidArgumentError and had to error catch. that's what this is\n",
        "#x_batch, y_batch = next(batch_gen(train_pairs, batch_size=4))\n",
        "#print(\"image shape:\", x_batch.shape, \"mask shape:\", y_batch.shape); print(\"unique labels:\", np.unique(y_batch)); print(\"max label:\", np.max(y_batch))\n",
        "N_CLASSES = int(np.max(y_batch)) + 1; #print(\"N_CLASSES =\", N_CLASSES)\n",
        "\n",
        "#pass the # of classes to build the model, for each each training rate\n",
        "for lr in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
        "    print(\"Training with lr =\", lr)\n",
        "    model = build_unet(num_classes=N_CLASSES)\n",
        "    opt = tf.keras.optimizers.Adam(lr) #get optimisation from tensorflow.keras, passing it each learning rate\n",
        "    model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])  # or masked accuracy\n",
        "    h = model.fit(train_gen, validation_data=val_gen, steps_per_epoch=len(train_pairs)//BATCH_SIZE, validation_steps=max(1, len(val_pairs)//BATCH_SIZE), epochs=EPOCHS)\n",
        "    histories[lr] = h.history\n",
        "\n",
        "#plot the training and validation loss curve at each learning rate\n",
        "plt.figure(figsize=(10,6))\n",
        "for lr, hist in histories.items():\n",
        "    plt.plot(hist['loss'], label=f\"train lr={lr}\")\n",
        "    plt.plot(hist['val_loss'], '--', label=f\"val lr={lr}\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss per learning rate\"); plt.legend(); plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ]
}